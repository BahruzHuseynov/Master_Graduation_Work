<div align="center">
   <h1> Master Graduation Work </h1>
   <h2> Comparison of Embedding models on Sarcasm Detection </h2>
   <img src = "https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcRmtkh90Gk2_vbKuZ1mSQV6RXvuXF54aofLTA&s" alt="ELTE Logo">
</div>
 </b>

## Technology
- **Python**: Main programming language. ![Python](https://img.shields.io/badge/Python-3776AB?style=for-the-badge&logo=python&logoColor=white)
- **PyTorch**: Machine Learning framework. <img src="https://github.com/tandpfun/skill-icons/blob/main/icons/PyTorch-Dark.svg" alt="PyTorch" width="30" />
- **Scikit-learn**: Machine Learning framework. <img src="https://upload.wikimedia.org/wikipedia/commons/thumb/0/05/Scikit_learn_logo_small.svg/1200px-Scikit_learn_logo_small.svg.png" alt="PyTorch" width="30" />

## Google Colab <img src="https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcSArk3D34rWqNoPw4_n-ovyK0lz3yvknTVZd9yeCdZrsdDEViqoPMmjhFWD-iy4NO1UiyI&usqp=CAU" alt="Colab" width="40">
- During research, codes have been executed in Google Colab as it is a hosted Jupyter Notebook service that provides free access to computing resources, including GPUs and TPUs.

## Datasets
1. Sarcasm Corpus v2:
   - https://github.com/soraby/sarcasm2
   - https://nlds.soe.ucsc.edu/sarcasm2
   - https://paperswithcode.com/dataset/sarcasm-corpus-v2
2. Sarcasm News Headlines
   - https://github.com/rishabhmisra/News-Headlines-Dataset-For-Sarcasm-Detection
3. iSarcasm


## Embedding models
<table>
   <tr>
      <th> Model </th>
      <th> Model size (million parameters) </th>
      <th> Memory usage (GB, fp32) </th>
      <th> Embedding dimension </th>
      <th> Max tokens </th>
      <th> Link </th>
   </tr>
   <tr>
      <td> cde-small-v1 </td>
      <td> 143 </td>
      <td> 0.53 </td>
      <td> 768 </td>
      <td> 512 </td>
      <td> https://huggingface.co/jxm/cde-small-v1 </td>
   </tr>
   <tr>
      <td> gte-base-en-v1.5 </td>
      <td> 137 </td>
      <td> 0.51 </td>
      <td> 768 </td>
      <td> 8192 </td>
      <td> https://huggingface.co/Alibaba-NLP/gte-base-en-v1.5 </td>
   </tr>
   <tr>
      <td> GIST-small-Embedding-v0 </td>
      <td> 33 </td>
      <td> 0.12 </td>
      <td> 384 </td>
      <td> 512 </td>
      <td> https://huggingface.co/avsolatorio/GIST-small-Embedding-v0 </td>
   </tr>
</table>

## Report
- Actual report and its editable format in LatEx is provided under this folder

## Results
